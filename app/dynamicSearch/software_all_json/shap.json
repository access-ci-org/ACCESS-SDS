{
  "software_name": "SHAP",
  "overview": "SHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. It connects game theory with local explanations, attributing the impact of each feature on a model's predictions.",
  "core_features": "1. Provides unified approach for explaining machine learning models.\n2. Utilizes Shapley values from cooperative game theory for local feature attributions.\n3. Supports various model types including tree-based models, deep learning models, and more.\n4. Helps understand the impact of individual features on model predictions.\n5. Enables model interpretability and transparency for better decision making.",
  "general_tags": ["explainability", "interpretability", "machine learning", "model explanation"],
  "research_discipline": ["Artificial Intelligence and Intelligent Systems"],
  "research_area": [],
  "software_class": "Library",
  "software_type": "Python Library",
  "field_of_science": "Computer and Information Sciences"
}