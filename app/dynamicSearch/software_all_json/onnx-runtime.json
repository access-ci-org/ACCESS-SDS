{
    "software_name": "ONNX Runtime",
    "comprehensive_overview": "ONNX Runtime is a high-performance scoring engine for Open Neural Network Exchange (ONNX) models. It provides an easy and efficient way to deploy and run ONNX models across a variety of hardware platforms and devices.",
    "core_features": [
        "Efficient inference of ONNX models",
        "Cross-platform support for Windows, Linux, and macOS",
        "Hardware acceleration with CUDA and TensorRT support",
        "Ability to integrate with various programming languages and frameworks like Python, C++, and .NET"
    ],
    "general_tags": [
        "Machine Learning",
        "Deep Learning",
        "Model Deployment",
        "Inference Engine"
    ],
    "additional_tags": {
        "research_discipline": [],
        "research_area": [],
        "software_class": "Deployment Tool",
        "software_type": "Runtime Engine",
        "field_of_science": [
            "Computer and Information Sciences",
            "Artificial Intelligence and Intelligent Systems"
        ]
    }
}