Use Case: MPI (Message Passing Interface) is commonly used in parallel computing for sending and receiving messages between processes. MPI can be used to parallelize scientific computations and simulations that require high computational power and large data sets, such as simulations of weather patterns or particle physics experiments.

Code Details and Examples: 
In an MPI program, each process has its own variables, and the processes coordinate by sending each other messages. This is a simple MPI program that sends a message from one process to another.

```c
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    MPI_Init(NULL, NULL);
    int rank;
    int world_size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &world_size);
    if (rank == 0) {
        int token = 0;
        MPI_Send(&token, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
        printf("Process 0 sent token %d to process 1\n", token);
    } else if (rank == 1) {
        int token;
        MPI_Recv(&token, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        printf("Process 1 received token %d from process 0\n", token);
    }
    MPI_Finalize();
}
```

This program initializes MPI, then gets the rank and world size (number of processes). If the rank is 0, it sends a token (in this case, an integer) to process 1. If the rank is 1, it receives the token from process 0. Note that MPI_Send and MPI_Recv are blocking operations; that is, they wait until the message has been sent or received before proceeding.

You can compile and run this program with the following commands:
```bash
mpicc -o mpi_example mpi_example.c
mpirun -np 2 ./mpi_example
```

Here, `mpicc` is a wrapper for the C compiler that links in the necessary MPI libraries, and `mpirun` is a utility for running MPI programs. The `-np 2` option specifies that the program should be run on 2 processes.