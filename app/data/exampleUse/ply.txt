Use Case: PLY is a Python library that simplifies the task of writing parsers. It is mainly used in situations where you need to write a special-purpose language or a language-to-language translator. PLY provides most of the standard lex/yacc features, but also includes some additional enhancements.

Code details and examples: 

Code:

```python
import ply.lex as lex

# List of token names
tokens = (
   'NUMBER',
   'PLUS',
   'MINUS',
   'TIMES',
   'DIVIDE',
   'LPAREN',
   'RPAREN',
)

# Regular expression rules for simple tokens
t_PLUS    = r'\+'
t_MINUS   = r'-'
t_TIMES   = r'\*'
t_DIVIDE  = r'/'
t_LPAREN  = r'\('
t_RPAREN  = r'\)'

# A regular expression rule with some action code
def t_NUMBER(t):
    r'\d+'
    t.value = int(t.value)   
    return t

# Define a rule so we can track line numbers
def t_newline(t):
    r'\n+'
    t.lexer.lineno += len(t.value)

# A string containing ignored characters (spaces and tabs)
t_ignore = ' \t'

# Error handling rule
def t_error(t):
    print("Illegal character '%s'" % t.value[0])
    t.lexer.skip(1)

# Build the lexer
lexer = lex.lex()
```

To use the lexer to tokenize input, you first have to feed it some input text using its input() method. After that, repeated calls to token() produce tokens.

Command to run them:

```python
# Test it out
data = '''
3 + 4 * 10
  + -20 *2
'''

# Give the lexer some input
lexer.input(data)

# Tokenize
for tok in lexer:
    print(tok)
```

In the above example, no specific input file is required. The data is hardcoded into the Python script. The specific lexer is designed to parse basic arithmetic operations (add, sub, mul, div) and parentheses. It can recognize numbers, +, -, *, /, ( and ) tokens. Each token is recognized based on specific regular expressions. This code will output a sequence of tokens recognized from the input string.
